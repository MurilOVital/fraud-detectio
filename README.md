# ğŸ›¡ï¸ Credit Card Fraud Detection - Machine Learning

Este projeto implementa e compara diferentes algoritmos de **aprendizado de mÃ¡quina** para detecÃ§Ã£o de transaÃ§Ãµes fraudulentas em um cenÃ¡rio **altamente desbalanceado**.  

ğŸ“Œ Desenvolvido como parte de uma disciplina de **InteligÃªncia Artificial** na **UTFPR - Apucarana**.

---

## ğŸ“Š Objetivo
Identificar padrÃµes em transaÃ§Ãµes financeiras e classificar transaÃ§Ãµes como legÃ­timas ou fraudulentas, analisando o desempenho de diferentes algoritmos.

---

## ğŸ“‚ Dataset
- **Fonte:** [Credit Card Fraud Detection Dataset (Kaggle)](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Total de transaÃ§Ãµes:** 284.807  
- **Fraudes:** 492 (0,172% do total)
- **Features:** 31 (incluindo 28 variÃ¡veis anonimizadas via PCA)

---

## ğŸ”§ Tecnologias Utilizadas
- **Linguagem:** Python  
- **Bibliotecas:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, XGBoost

---

## ğŸ“Œ Metodologia
1. **AnÃ¡lise ExploratÃ³ria (EDA)** â€” visualizaÃ§Ã£o da distribuiÃ§Ã£o das variÃ¡veis e identificaÃ§Ã£o de desbalanceamento.  
2. **PrÃ©-processamento** â€” escalonamento de variÃ¡veis, ajuste de pesos de classes, tratamento do desbalanceamento.  
3. **Treinamento** â€” divisÃ£o dos dados (70% treino, 30% teste).  
4. **AvaliaÃ§Ã£o** â€” uso de mÃ©tricas como *Accuracy*, *Precision*, *Recall* e *F1-score*.  

---

## ğŸ¤– Modelos Testados
- Random Forest
- Random Forest + Isolation Forest
- XGBoost
- RegressÃ£o LogÃ­stica (baseline)

---

## ğŸ“ˆ Resultados

| Modelo                          | AcurÃ¡cia | PrecisÃ£o | Recall | F1-score |
|--------------------------------|----------|----------|--------|----------|
| Random Forest                  | 1.00     | 0.96     | 0.71   | 0.82     |
| Random Forest + IsolationForest| 1.00     | 0.96     | 0.73   | 0.83     |
| **XGBoost**                    | **1.00** | **0.96** | **0.75** | **0.84** |
| RegressÃ£o LogÃ­stica             | 0.97     | 0.05     | 0.89   | 0.10     |

---

## ğŸ“Š Matrizes de ConfusÃ£o
ğŸ“Œ *Substitua os exemplos abaixo pelas imagens reais geradas durante o treinamento.*

**Random Forest**  
![Random Forest](img/matriz_random.png)

**Random Forest + Isolation Forest**  
![RF + Isolation Forest](img/matriz_isolation.png)

**XGBoost**  
![XGBoost](img/matriz_xg.png)

**RegressÃ£o LogÃ­stica**  
![Logistic Regression](img/matriz_logistic.png)

---

## ğŸ” ConclusÃµes
- **Melhor modelo:** `XGBoost` (F1-score = 0.84), alcanÃ§ando bom equilÃ­brio entre *precision* e *recall*.  
- **CombinaÃ§Ã£o de modelos** (Random Forest + Isolation Forest) apresentou melhora no recall sem perder precisÃ£o.  
- **RegressÃ£o LogÃ­stica** teve baixo desempenho devido ao grande nÃºmero de falsos positivos.  
- Algoritmos baseados em Ã¡rvores e boosting mostraram-se mais adequados para bases altamente desbalanceadas.

---

## ğŸ‘¨â€ğŸ’» Autores
- Mabylly Kauany Neres da Silva  
- Murilo Vital Rondina  
- Ruan Mateus Trizotti
